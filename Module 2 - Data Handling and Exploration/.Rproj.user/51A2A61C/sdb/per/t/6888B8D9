{
    "collab_server" : "",
    "contents" : "---\ntitle: \"Common Transformations\"\nauthor: \"Irfan Kanat\"\ndate: \"July 4, 2017\"\noutput:\n  html_document: default\n  pdf_document: default\ngeometry: margin=1in\nurlcolor: blue\n---\n\n```{r, echo=FALSE, results='hide', warning=F, error=F, message=F}\nlibrary(ggplot2)\nlibrary(gridExtra)\nlibrary(psych)\n```\n\nIn this learning activity we will learn about when and why transforming data may be justified as well as some common transformations.\n\nGoing back to our discussion of normal distribution, mean and standard deviation in Descriptive Statistics learning activity, sometimes the distribution of variables, or the sheer scale (number of rooms 1-10, versus the price of a house 100000-3000000) makes comparisons difficult. Especially if you want to compare the effect sizes in statistical models some sort of transformation is useful.\n\nAnother reason for transformation is that the variable is not normally distributed and the broad variance may obfuscate an otherwise legitimate relation.\n\n## Introducing the Data\n\nYou may remember the **ZRI Summary: Multifamily, SFR, Condo/Co-op (Current Month)** dataset from Assignment 1. I will use the same dataset for demonstration purposes.\n\n```{r}\nzillow<-read.csv(\"data/zillow.csv\")\nView(zillow)\n```\n\nAnother dataset we will use today is SAT and ACT scores from the psych package (you do know how to obtain and activate packages).\n\n```{r}\ndata(sat.act)\n?sat.act\n```\n\n## Transformations for Non-Normal Data\n\nThe methods discussed below will bring your data closer to a normal distribution. But you should be aware of the caveat. The coefficients estimated in models with transformed variables do not mean the same thing. So take heed in presenting results of transformed data. What needs to be done depends on the type of transformation. \n\n### Right Skewed Data\n\nPrices, wages, wealth or other monetary figures often follow a power law distribution. This means you will have lots of observations on the left hand side of the scale and a handful of very large amounts on the right hand side. To help you visualize imagine how many people live on minimum wage, that is the left hand side. Now imagine how many people earn over 5 million dollars, that is the far right end.\n\nIf your goal is prediction the independent variable not being normally distributed is not an issue at all, but in some cases an otherwise significant relation may show up non-significant. Hence it is a good idea to transform these variables (or take the outliers out somehow).\n\nLet us look at the distribution of zillow rent index. This is not a perfect example, yet it is sufficiently similar for our purposes. By now you know how qplot works. I will take some shortcuts and skip a few optional parameters.\n\n```{r}\nqplot(zillow$Zri)\n```\n\nMost places in the country have rents that are below \\$2000, so you see high, easy to see bars on the left. There is virtually 0 free homes, so the x axis starts somewhere around \\$500. What you don't see is why the right hand side of the plot keeps going up to $17000. \n\nThere are two counties in California where the rents are above $15000. That push the boundary way out into \\$16600 range.\n\nHere is a little exercise for you. Using the filtering skills we reviewed in Descriptive Statistics learning activity, find out which counties have rents indexes higher than $15000.\n\n*Log Transformation*\n\nA common transformation used in powerlaw distribution is log transformations. You basically take the natural logarithm of the variable. To understand why it would work, observe the examples below.\n\n```{r}\nlog(500)   # logarithm of $500 is 6.2\nlog(1500)  # $1500 is 7.3\nlog(15000) # $15000 is 9.6\n```\n\nThe log transformations shrinks the higher values more than it does the lower values, hence pulling those extreme observations back into the fold. In a sense, it gets rid of outliers without sacrificing data points. \n\nLet us see what happens in a visual example.\n\n```{r}\np1<-qplot(zillow$Zri)\np2<-qplot(log(zillow$Zri))\ngrid.arrange(p1, p2, ncol=2)\n```\n\nNote the differences on scale in both x and y axes. While not perfect, log transformed zillow rent index looks a lot more normal compared to untransformed version.\n\nYou can always use log() function in models, but if you want to store transformed variable you can do it as follows:\n\n```{r}\nzillow$logZri<-log(zillow$Zri) # Create a new column and store transformed values in this column.\nhead(zillow[,c(\"logZri\", \"Zri\")])\n```\n\nWhen data is transformed this way, you need to take heed in interpreting coefficients. The beta coefficient no longer stands for a 1 unit change in ZRI.\n\nAnother issue you should be aware of is that log transformation only works with positive values.\n\n```{r}\nlog(0)\nlog(-5)\n```\n\nIf your data has zeros you can simply add 1 to all observations, for negative values cube rooting instead of log transformation may help.\n\n*Square Root Transformation*\n\nAn alternative to log transformation is taking square root of the variable. It works the same way as log transformation, in the sense that it shrinks the larger values more, hence brings them closer to the rest of the data. Depending on your data a square root may provide better results (in this case it doesn't).\n\nLet us see visually.\n\n```{r}\np3<-qplot(sqrt(zillow$Zri))\ngrid.arrange(p1, p2, p3, ncol=3)\n```\n\nAgain, square root transformation does not work with negative values, but it works with 0s.\n\n```{r}\nsqrt(0)\nsqrt(-5)\n```\nHere is a simple exercise for you, calculate square root transformed ZRI and store it in a new column called sqrtZri.\n\n### Left Skewed Data\n\nSome values such as aptitude scores are left skewed, with majority of the observations on the right hand side and just a few observations on the left. \n\nSAT scores are traditionally of this kind. \n\nLet us see:\n\n```{r}\nqplot(sat.act$SATQ, binwidth=25)\n```\n\n**Square Transformation**\n\nIf your data is left skewed taking the square of the values may help a bit. Let us see.\n\n```{r}\np1<-qplot(sat.act$SATQ)\np2<-qplot((sat.act$SATQ)^2)\noptions(scipen=99)\ngrid.arrange(p1, p2, ncol=2)\n```\n\nYou can see the transformed values look a *bit* more normal. You should not expect miracles.\n\nHere is another exercise, square transform SATV scores and store them in a new column called SATV2.\n\n### Box-Cox Transformation\n\nA more advanced version of log transformation is box-cox transformation. It finds the exact base to transform the data, so will generally produce distributions closer to normal. Another advantage is that it will work with both left and right skewed data. I have never seen a big enough difference between common transformations and box-cox transformations, so I will spare you the details.\n\n## Normalization / Standardization\n\nThere may be certain cases where you may want to normalize data. Certain types of analysis (Principal Component Analysis) would be sensitive to differences in scale for example. Another case would be to compare coefficients. The coefficients would mean one thing for a variable that ranges between 1000000 and 5000000, and another for a variable that ranges between 1 and 5.\n\nStandardization in our case is substracting the mean value from each observation and dividing the remainder by sd. The result is the variable will have a mean of 0 and a standard deviation of 1. If all variables are standardized, the coefficients will mean exactly the same thing for each variable.\n\nLet us standardize the Zillow Rent Index in zillow dataset and store it in a variable called stdZri.\n\n```{r}\nzillow$stdZri<-scale(zillow$Zri)\n# Let us verify that the data is indeed standardized\nmean(zillow$stdZri) # Looks good\nsd(zillow$stdZri) # Looks good\n# Let us see how the results look compared to non transformed values.\nhead(zillow[,c(\"Zri\",\"stdZri\")])\n```\n\nRemember the mean Zri is `r round(mean(zillow$Zri))`. So values higher than the mean Zri are positive whereas values lower than Zri are negative.\n\n\n## Solution to Exercises\n\n1. Find out which counties have rents indexes higher than $15000.\n\n```{r}\nzillow[zillow$Zri>15000,]\n```\n\n2. Calculate square root transformed ZRI and store it in a new column called sqrtZri.\n\n```{r}\nzillow$sqrtZri<-sqrt(zillow$Zri)\n```\n\n3. Square transform SATV scores and store them in a new column called SATV2.\n\n```{r}\nsat.act$SATV2<-(sat.act$SATV)^2\n```",
    "created" : 1499207771763.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1602743749",
    "id" : "6888B8D9",
    "lastKnownWriteTime" : 1499208110,
    "last_content_update" : 1499208110702,
    "path" : "~/Dropbox/QBAXXXX/R Content/Week 2 - Data Handling and Exploration/5_Transformations.Rmd",
    "project_path" : "5_Transformations.Rmd",
    "properties" : {
    },
    "relative_order" : 13,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}