{
    "collab_server" : "",
    "contents" : "---\ntitle: \"Outliers and Influential Observations\"\nauthor: \"Irfan Kanat\"\ndate: \"August 13, 2017\"\noutput:\n  html_document: default\n  pdf_document: default\ngeometry: margin=1in\nurlcolor: blue\n---\n\n```{r setup, include=FALSE}\nlibrary(ggplot2)\nlibrary(texreg) # To lay two model results side by side\nlibrary(gridExtra) # To lay two separate plots side by side\nload(\"data/develop_fit\")\n```\n\n# Outliers and Why They Are Important\n\nOutliers are extreme observations in a sample. The reason we care about them is that they can bias the fit quite drastically. Let me demonstrate with an example:\n\nYou remember develop dataset from Interactions learning activity. Let us say that two aliens who were visiting the planet made a mistake in their height calculations (must be the imperial system) and disguised themselves as 4 m tall (13 ft) 10 year olds.\n\nHere I will use a smaller dataset as outliers' effects are dampened a bit with a larger dataset. One or two observations will have less of an effect in a larger dataset. **I AM REPEATING THIS AS IT IS IMPORTANT: Outliers are less of a concern in a larger dataset.**\n\n```{r}\n# I am reducing the sample size so that the effect of outliers is more pronounced.\ndevelopSmall <- develop[1:30, ]\n# Adding the aliens\ndevelopOut <- rbind(develop[1:30, ], data.frame(gender = 0:1, age = c(10:10),\n                                                height = c(399, 400)))\n# Fitting the model with reduced sample\ndevelopSmall_lm_0 <- lm(height ~ gender + age, data = developSmall)\n# Fitting the model with aliens\ndevelopOut_lm_0 <- lm(height ~ gender + age, data = developOut)\n```\n\nLet us compare the two fits. (I will use screenreg to print two models side by side, you will need texreg package for this).\n\n```{r}\nscreenreg(list(developSmall_lm_0, developOut_lm_0))\nsummary(developSmall_lm_0)$fstatistic # Compare F statistics\nsummary(developOut_lm_0)$fstatistic\n```\n\nYou will see that our variable estimates turned insignificant. The model's explanatory power has suffered. Furthermore, looking at F statistic, the model with outliers is basically unusable. \n\nLet us visually inspect how the outlier model compares to small model.\n\nFirst off, fitted values to actual values for both models.\n\n```{r}\n# Easy to remember, easy to follow\nplotDevSmall <- qplot(x = developSmall_lm_0$fitted.values,\n                      y = developSmall$height, geom = \"point\") +\n  ggtitle(\"Small\") + xlab(\"Estimated\") + ylab(\"Actual\") + ylim(0, 400) +\n  xlim(0, 400) + theme_bw()\n# Directly uses the model, but have to remember .resid and .fitted\n# plotDevSmall<-ggplot(developSmall_lm_0, aes(.fitted, .resid))+ geom_point()\n\nplotDevOut <- qplot(x = developOut_lm_0$fitted.values,\n                    y = developOut$height, geom = \"point\") +\n  ggtitle(\"Outlier\") + xlab(\"Estimated\") + ylab(\"Actual\") + ylim(0, 400) +\n  xlim(0, 400) + theme_bw()\n\ngrid.arrange(plotDevSmall, plotDevOut, nrow = 1)\n```\n\nOn the X axis you see our guess for what the person's height would be. Y axis is their actual height. If we made perfect predictions the points would lie on a 45 degree angle (assuming x and y axes are on same scale).\n\nOriginal model is a pretty good fit. Whereas with outliers our guesses are wildly inaccurate.\n\nHow inaccurate? Let us inspect residual plots.\n\n```{r}\nplotDevSmall <- qplot(x = developSmall_lm_0$fitted.values,\n                      y = developSmall_lm_0$residuals, geom = \"point\") +\n  ylim(-100, 300) + xlim(90, 200) + theme_bw()\n\nplotDevOut <- qplot(x = developOut_lm_0$fitted.values,\n                    y = developOut_lm_0$residuals, geom = \"point\") +\n  ylim(-100, 300) + xlim(90, 200) + theme_bw()\n\ngrid.arrange(plotDevSmall, plotDevOut, nrow = 1)\n```\nYou can see the model with outliers has more variance (remember less variance in residuals means more accuracy in estimates) in residuals. Also it fits the values into a narrower band.\n\nIn both plots we can clearly see the outliers. Unfortunately, in real life making the call for outliers is not as easy as spotting 13ft tall school kids.\n\n## Univariate Approaches to Outlier Detection\n\nIf the idea is extreme observations, we can use the normal distribution to guide us in detecting them. As you may have learned (when conducting T tests) 95.4% of the observations are expected to be 2 standard deviations around the mean. We can use this to say if an observation is beyond 3 standard deviations from the mean that would be an extreme observation.\n\nSimply calculate the mean, and determine cut-off values based on standard deviation. \n\n```{r}\nu <- mean(developOut$height) # Get the mean\ns <- sd(developOut$height) # Get the sd\n\nupper <- u + 3 * s # any kid taller than this would be an outlier\nlower <- u - 3 * s # any kid shorter than this would be an outlier\n# Filter the outliers\ndevelopOut[developOut$height > upper | developOut$height < lower, ]\n```\n\nYou already know how to remove observations that you filtered from Module 2. So here is a simple exercise for you: Create a new dataset from developOut that does not have the outliers in.\n\nVisually you can inspect the boxplots.\n\n```{r}\n# Create A Boolean (True False) Vector for Outliers to use in labeling\noutlier <- (developOut$height > upper | developOut$height < lower) # True/False\noutlier[outlier] <- which(outlier) # Put the row number in\noutlier[outlier == 0] <- \"\" # Leave blank if not outlier\n# Create a boxplot\nqplot(data = developOut, x = factor(gender), y = height, geom = \"boxplot\") +\n  # Label the outliers by row numbers\n  geom_text(aes(label = outlier), na.rm = T, hjust = -0.4)\n```\n\nYou can change the criteria. I used 3 standard deviations. That assumes a normal distribution. Instead you can use quartiles for example.\n\nHere is a simple exercise for you, I used row numbers to identify outliers. Can you print the height of the outliers instead?\n\n# Multivariate Approaches to Outlier Detection\n\nIt is good to know if certain observations are extreme or not, but do they really have an extraordinary impact in your model? You may discard datapoints because they are different, but what if the variable they were abnormal on was not that significant in your model anyway?\n\nWouldn't it be nice to have a test that is specific to the model you are fitting? Say if an observation is changing the model fit more than others? If an observation is more influential?\n\n## Cook's Distance\n\nWith Cook's Distance, we compare mean estimate when an observation is present versus when an observation is removed. How much does the overall estimation change when we remove a variable? For an influential observation, we expect this change (distance) to be large.\n\nHere is how we calculate cooks distance in R:\n\n```{r}\ncooks.distance(developOut_lm_0) # This gives us a distance calculated for each observation.\n```\nGenerally speaking we would assume an observation is an outlier if the cooks distance is greater than 4 times the average cooks distance for the model.\n\n```{r}\ncd <- cooks.distance(developOut_lm_0) # Save distances in an array\ncd[cd > mean(cd) * 4] # Filter the distances that are greater than 4 times the mean distance.\n```\n\nLet us visualize\n\n```{r}\nqplot(y = cd, x = seq_along(cd)) + geom_bar(stat=\"identity\") +  # Easy to remember\n  geom_hline(yintercept = mean(cd * 4), col=\"red\") + # Add a line at 4 times the mean of cook's distance\n  xlab(\"Observations\") + ylab(\"Cook's Distance\") + theme_bw()\n  \n#ggplot(developOut_lm_0, aes(seq_along(.cooksd), .cooksd))+ # Directly uses fitted model\n# geom_bar(stat=\"identity\", position=\"identity\")+ \n# geom_hline(yintercept=mean(cd*4),col=\"red\")+\n# xlab(\"Observations\") + ylab(\"Cook's Distance\") + theme_bw()\n```\n\n# Exercises\n\n1 - Create a new dataset from developOut that does not have the outliers in it.\n\n```{r}\ndevelopIn <- developOut[!(developOut$height > upper | developOut$height < lower), ]\ntail(developIn)\n```\n\n2 - I used row numbers to identify outliers. Can you print the height of the outliers instead? \n\n```{r}\n# Create A Boolean (True False) Vector for Outliers to use in labeling\noutlier <- (developOut$height > upper | developOut$height < lower) # Outlier?\noutlier[outlier] <- developOut[outlier, \"height\"] # Put the row number in\noutlier[outlier == 0] <- \"\" # Leave blank if not outlier\n# Create a boxplot\nqplot(data = developOut, x = factor(gender), y = height) + geom_boxplot() +\n  # Label the outliers by height\n  geom_text(aes(label = outlier), na.rm = T, hjust = -0.4)\n```",
    "created" : 1502720737522.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "631169012",
    "id" : "A93DBD2E",
    "lastKnownWriteTime" : 1504119509,
    "last_content_update" : 1504119509214,
    "path" : "~/Dropbox/QBAXXXX/R Content/Module 3 - Continous Modelling/4_Outliers.Rmd",
    "project_path" : "4_Outliers.Rmd",
    "properties" : {
        "last_setup_crc32" : ""
    },
    "relative_order" : 8,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}